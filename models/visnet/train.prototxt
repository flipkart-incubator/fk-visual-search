name: "Visnet"
layer {
  name: "data_q"
  type: "ImageData"
  top: "data_q"
  top: "label_q"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "<path to train q file>"
    batch_size: 20
  }
}
layer {
  name: "data_q"
  type: "ImageData"
  top: "data_q"
  top: "label_q"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "<path to test q file>"
    batch_size: 20
  }
}
layer {
  name: "data_q2"
  type: "Pooling"
  bottom: "data_q"
  top: "data_q2"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "data_q3"
  type: "Pooling"
  bottom: "data_q"
  top: "data_q3"
  pooling_param {
    pool: MAX
    kernel_size: 8
    stride: 8
  }
}

layer {
  name: "data_p"
  type: "ImageData"
  top: "data_p"
  top: "label_p"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "<path to train p file>"
    batch_size: 20
  }
}
layer {
  name: "data_p"
  type: "ImageData"
  top: "data_p"
  top: "label_p"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "<path to test p file>"
    batch_size: 20
  }
}

layer {
  name: "data_p2"
  type: "Pooling"
  bottom: "data_p"
  top: "data_p2"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "data_p3"
  type: "Pooling"
  bottom: "data_p"
  top: "data_p3"
  pooling_param {
    pool: MAX
    kernel_size: 8
    stride: 8
  }
}

layer {
  name: "data_n"
  type: "ImageData"
  top: "data_n"
  top: "label_n"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "<path to train n file>"
    batch_size: 20
  }
}
layer {
  name: "data_n"
  type: "ImageData"
  top: "data_n"
  top: "label_n"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 224
  }
  image_data_param {
    source: "<path to test n file>"
    batch_size: 20
  }
}

layer {
  name: "data_n2"
  type: "Pooling"
  bottom: "data_n"
  top: "data_n2"
  pooling_param {
    pool: MAX
    kernel_size: 4
    stride: 4
  }
}
layer {
  name: "data_n3"
  type: "Pooling"
  bottom: "data_n"
  top: "data_n3"
  pooling_param {
    pool: MAX
    kernel_size: 8
    stride: 8
  }
}

#Q
layer {
  bottom: "data_q"
  top: "conv1_1_q"
  name: "conv1_1"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv1_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv1_1_q"
  top: "conv1_1_q"
  name: "relu1_1"
  type: "ReLU"
}
layer {
  bottom: "conv1_1_q"
  top: "conv1_2_q"
  name: "conv1_2"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv1_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv1_2_q"
  top: "conv1_2_q"
  name: "relu1_2"
  type: "ReLU"
}
layer {
  bottom: "conv1_2_q"
  top: "pool1_q"
  name: "pool1"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool1_q"
  top: "conv2_1_q"
  name: "conv2_1"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv2_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv2_1_q"
  top: "conv2_1_q"
  name: "relu2_1"
  type: "ReLU"
}
layer {
  bottom: "conv2_1_q"
  top: "conv2_2_q"
  name: "conv2_2"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv2_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv2_2_q"
  top: "conv2_2_q"
  name: "relu2_2"
  type: "ReLU"
}
layer {
  bottom: "conv2_2_q"
  top: "pool2_q"
  name: "pool2"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool2_q"
  top: "conv3_1_q"
  name: "conv3_1"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_1_q"
  top: "conv3_1_q"
  name: "relu3_1"
  type: "ReLU"
}
layer {
  bottom: "conv3_1_q"
  top: "conv3_2_q"
  name: "conv3_2"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_2_q"
  top: "conv3_2_q"
  name: "relu3_2"
  type: "ReLU"
}
layer {
  bottom: "conv3_2_q"
  top: "conv3_3_q"
  name: "conv3_3"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_3_q"
  top: "conv3_3_q"
  name: "relu3_3"
  type: "ReLU"
}
layer {
  bottom: "conv3_3_q"
  top: "pool3_q"
  name: "pool3"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool3_q"
  top: "conv4_1_q"
  name: "conv4_1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_1_q"
  top: "conv4_1_q"
  name: "relu4_1"
  type: "ReLU"
}
layer {
  bottom: "conv4_1_q"
  top: "conv4_2_q"
  name: "conv4_2"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_2_q"
  top: "conv4_2_q"
  name: "relu4_2"
  type: "ReLU"
}
layer {
  bottom: "conv4_2_q"
  top: "conv4_3_q"
  name: "conv4_3"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_3_q"
  top: "conv4_3_q"
  name: "relu4_3"
  type: "ReLU"
}
layer {
  bottom: "conv4_3_q"
  top: "pool4_q"
  name: "pool4"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool4_q"
  top: "conv5_1_q"
  name: "conv5_1"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_1_q"
  top: "conv5_1_q"
  name: "relu5_1"
  type: "ReLU"
}
layer {
  bottom: "conv5_1_q"
  top: "conv5_2_q"
  name: "conv5_2"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_2_q"
  top: "conv5_2_q"
  name: "relu5_2"
  type: "ReLU"
}
layer {
  bottom: "conv5_2_q"
  top: "conv5_3_q"
  name: "conv5_3"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_3_q"
  top: "conv5_3_q"
  name: "relu5_3"
  type: "ReLU"
}
layer {
  bottom: "conv5_3_q"
  top: "pool5_q"
  name: "pool5"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool5_q"
  top: "fc6_q"
  name: "fc6"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc6_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc6_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "fc6_q"
  top: "fc6_q"
  name: "relu6"
  type: "ReLU"
}
layer {
  bottom: "fc6_q"
  top: "fc6_q"
  name: "drop6"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  bottom: "fc6_q"
  top: "fc7_q"
  name: "fc7"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc7_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc7_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "fc7_q"
  top: "fc7_q"
  name: "relu7"
  type: "ReLU"
}
layer {
  bottom: "fc7_q"
  top: "fc7_q"
  name: "drop7"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  bottom: "fc7_q"
  top: "fc8_q"
  name: "fc8_q"
  type: "InnerProduct"
  param {
    name: "fc8_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc8_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}

layer {
  name: "reshape_q"
  type: "Reshape"
  bottom: "fc8_q"
  top: "fc8_q_r"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "fc8_q_norm"
  type: "LRN"
  bottom: "fc8_q_r"
  top: "fc8_q_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191
    beta: 0.5
  }
}

#P
layer {
  bottom: "data_p"
  top: "conv1_1_p"
  name: "conv1_1_p"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv1_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv1_1_p"
  top: "conv1_1_p"
  name: "relu1_1_p"
  type: "ReLU"
}
layer {
  bottom: "conv1_1_p"
  top: "conv1_2_p"
  name: "conv1_2_p"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv1_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv1_2_p"
  top: "conv1_2_p"
  name: "relu1_2_p"
  type: "ReLU"
}
layer {
  bottom: "conv1_2_p"
  top: "pool1_p"
  name: "pool1_p"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool1_p"
  top: "conv2_1_p"
  name: "conv2_1_p"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv2_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv2_1_p"
  top: "conv2_1_p"
  name: "relu2_1_p"
  type: "ReLU"
}
layer {
  bottom: "conv2_1_p"
  top: "conv2_2_p"
  name: "conv2_2_p"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv2_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv2_2_p"
  top: "conv2_2_p"
  name: "relu2_2_p"
  type: "ReLU"
}
layer {
  bottom: "conv2_2_p"
  top: "pool2_p"
  name: "pool2_p"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool2_p"
  top: "conv3_1_p"
  name: "conv3_1_p"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_1_p"
  top: "conv3_1_p"
  name: "relu3_1_p"
  type: "ReLU"
}
layer {
  bottom: "conv3_1_p"
  top: "conv3_2_p"
  name: "conv3_2_p"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_2_p"
  top: "conv3_2_p"
  name: "relu3_2_p"
  type: "ReLU"
}
layer {
  bottom: "conv3_2_p"
  top: "conv3_3_p"
  name: "conv3_3_p"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_3_p"
  top: "conv3_3_p"
  name: "relu3_3_p"
  type: "ReLU"
}
layer {
  bottom: "conv3_3_p"
  top: "pool3_p"
  name: "pool3_p"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool3_p"
  top: "conv4_1_p"
  name: "conv4_1_p"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_1_p"
  top: "conv4_1_p"
  name: "relu4_1_p"
  type: "ReLU"
}
layer {
  bottom: "conv4_1_p"
  top: "conv4_2_p"
  name: "conv4_2_p"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_2_p"
  top: "conv4_2_p"
  name: "relu4_2_p"
  type: "ReLU"
}
layer {
  bottom: "conv4_2_p"
  top: "conv4_3_p"
  name: "conv4_3_p"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_3_p"
  top: "conv4_3_p"
  name: "relu4_3_p"
  type: "ReLU"
}
layer {
  bottom: "conv4_3_p"
  top: "pool4_p"
  name: "pool4_p"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool4_p"
  top: "conv5_1_p"
  name: "conv5_1_p"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_1_p"
  top: "conv5_1_p"
  name: "relu5_1_p"
  type: "ReLU"
}
layer {
  bottom: "conv5_1_p"
  top: "conv5_2_p"
  name: "conv5_2_p"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_2_p"
  top: "conv5_2_p"
  name: "relu5_2_p"
  type: "ReLU"
}
layer {
  bottom: "conv5_2_p"
  top: "conv5_3_p"
  name: "conv5_3_p"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_3_p"
  top: "conv5_3_p"
  name: "relu5_3_p"
  type: "ReLU"
}
layer {
  bottom: "conv5_3_p"
  top: "pool5_p"
  name: "pool5_p"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool5_p"
  top: "fc6_p"
  name: "fc6_p"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc6_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc6_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "fc6_p"
  top: "fc6_p"
  name: "relu6_p"
  type: "ReLU"
}
layer {
  bottom: "fc6_p"
  top: "fc6_p"
  name: "drop6_p"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  bottom: "fc6_p"
  top: "fc7_p"
  name: "fc7_p"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc7_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc7_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "fc7_p"
  top: "fc7_p"
  name: "relu7_p"
  type: "ReLU"
}
layer {
  bottom: "fc7_p"
  top: "fc7_p"
  name: "drop7_p"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  bottom: "fc7_p"
  top: "fc8_p"
  name: "fc8_p"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc8_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc8_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}

layer {
  name: "reshape_p"
  type: "Reshape"
  bottom: "fc8_p"
  top: "fc8_p_r"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "fc8_p_norm"
  type: "LRN"
  bottom: "fc8_p_r"
  top: "fc8_p_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191
    beta: 0.5
  }
}

#N
layer {
  bottom: "data_n"
  top: "conv1_1_n"
  name: "conv1_1_n"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv1_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv1_1_n"
  top: "conv1_1_n"
  name: "relu1_1_n"
  type: "ReLU"
}
layer {
  bottom: "conv1_1_n"
  top: "conv1_2_n"
  name: "conv1_2_n"
  type: "Convolution"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv1_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv1_2_n"
  top: "conv1_2_n"
  name: "relu1_2_n"
  type: "ReLU"
}
layer {
  bottom: "conv1_2_n"
  top: "pool1_n"
  name: "pool1_n"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool1_n"
  top: "conv2_1_n"
  name: "conv2_1_n"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv2_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv2_1_n"
  top: "conv2_1_n"
  name: "relu2_1_n"
  type: "ReLU"
}
layer {
  bottom: "conv2_1_n"
  top: "conv2_2_n"
  name: "conv2_2_n"
  type: "Convolution"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv2_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv2_2_n"
  top: "conv2_2_n"
  name: "relu2_2_n"
  type: "ReLU"
}
layer {
  bottom: "conv2_2_n"
  top: "pool2_n"
  name: "pool2_n"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool2_n"
  top: "conv3_1_n"
  name: "conv3_1_n"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_1_n"
  top: "conv3_1_n"
  name: "relu3_1_n"
  type: "ReLU"
}
layer {
  bottom: "conv3_1_n"
  top: "conv3_2_n"
  name: "conv3_2_n"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_2_n"
  top: "conv3_2_n"
  name: "relu3_2_n"
  type: "ReLU"
}
layer {
  bottom: "conv3_2_n"
  top: "conv3_3_n"
  name: "conv3_3_n"
  type: "Convolution"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv3_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv3_3_n"
  top: "conv3_3_n"
  name: "relu3_3_n"
  type: "ReLU"
}
layer {
  bottom: "conv3_3_n"
  top: "pool3_n"
  name: "pool3_n"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool3_n"
  top: "conv4_1_n"
  name: "conv4_1_n"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_1_n"
  top: "conv4_1_n"
  name: "relu4_1_n"
  type: "ReLU"
}
layer {
  bottom: "conv4_1_n"
  top: "conv4_2_n"
  name: "conv4_2_n"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_2_n"
  top: "conv4_2_n"
  name: "relu4_2_n"
  type: "ReLU"
}
layer {
  bottom: "conv4_2_n"
  top: "conv4_3_n"
  name: "conv4_3_n"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv4_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv4_3_n"
  top: "conv4_3_n"
  name: "relu4_3_n"
  type: "ReLU"
}
layer {
  bottom: "conv4_3_n"
  top: "pool4_n"
  name: "pool4_n"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool4_n"
  top: "conv5_1_n"
  name: "conv5_1_n"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_1_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_1_n"
  top: "conv5_1_n"
  name: "relu5_1_n"
  type: "ReLU"
}
layer {
  bottom: "conv5_1_n"
  top: "conv5_2_n"
  name: "conv5_2_n"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_2_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_2_n"
  top: "conv5_2_n"
  name: "relu5_2_n"
  type: "ReLU"
}
layer {
  bottom: "conv5_2_n"
  top: "conv5_3_n"
  name: "conv5_3_n"
  type: "Convolution"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
  param {
    name: "conv5_3_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "conv5_3_n"
  top: "conv5_3_n"
  name: "relu5_3_n"
  type: "ReLU"
}
layer {
  bottom: "conv5_3_n"
  top: "pool5_n"
  name: "pool5_n"
  type: "Pooling"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  bottom: "pool5_n"
  top: "fc6_n"
  name: "fc6_n"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc6_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc6_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "fc6_n"
  top: "fc6_n"
  name: "relu6_n"
  type: "ReLU"
}
layer {
  bottom: "fc6_n"
  top: "fc6_n"
  name: "drop6_n"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  bottom: "fc6_n"
  top: "fc7_n"
  name: "fc7_n"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc7_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc7_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}
layer {
  bottom: "fc7_n"
  top: "fc7_n"
  name: "relu7_n"
  type: "ReLU"
}
layer {
  bottom: "fc7_n"
  top: "fc7_n"
  name: "drop7_n"
  type: "Dropout"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  bottom: "fc7_n"
  top: "fc8_n"
  name: "fc8_n"
  type: "InnerProduct"
  inner_product_param {
    num_output: 4096
  }
  param {
    name: "fc8_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "fc8_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
}

layer {
  name: "reshape_n"
  type: "Reshape"
  bottom: "fc8_n"
  top: "fc8_n_r"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "fc8_n_norm"
  type: "LRN"
  bottom: "fc8_n_r"
  top: "fc8_n_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191
    beta: 0.5
  }
}

#Q shallow

layer {
  name: "conv1_q2"
  type: "Convolution"
  bottom: "data_q2"
  top: "conv1_q2"
  param {
    name: "conv1_shallow_w2"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_shallow_b2"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 96
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    pad_h: 4
    pad_w: 4
  }
}
layer {
  name: "relu1_q2"
  type: "ReLU"
  bottom: "conv1_q2"
  top: "conv1_q2"
}

layer {
  name: "norm1_q2"
  type: "LRN"
  bottom: "conv1_q2"
  top: "norm1_q2"
  lrn_param {
    local_size: 5
    alpha: 9.99999974738e-05
    beta: 0.75
  }
}
layer {
  name: "pool1_q2"
  type: "Pooling"
  bottom: "norm1_q2"
  top: "pool1_q2"
  pooling_param {
    pool: MAX
    kernel_size: 7
    stride: 4
    pad_h: 3
    pad_w: 3
  }
}

layer {
  name: "conv1_q3"
  type: "Convolution"
  bottom: "data_q3"
  top: "conv1_q3"
  param {
    name: "conv1_shallow_w3"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_shallow_b3"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 96
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    pad_h: 4
    pad_w: 4
  }
}
layer {
  name: "relu1_q3"
  type: "ReLU"
  bottom: "conv1_q3"
  top: "conv1_q3"
}

layer {
  name: "norm1_q3"
  type: "LRN"
  bottom: "conv1_q3"
  top: "norm1_q3"
  lrn_param {
    local_size: 5
    alpha: 9.99999974738e-05
    beta: 0.75
  }
}
layer {
  name: "pool1_q3"
  type: "Pooling"
  bottom: "norm1_q3"
  top: "pool1_q3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 1
    pad_w: 1
  }
}

layer {
  name: "pool1_q2_flat"
  type: "Flatten"
  bottom: "pool1_q2"
  top: "pool1_q2_flat"
}
layer {
  name: "pool1_q3_flat"
  type: "Flatten"
  bottom: "pool1_q3"
  top: "pool1_q3_flat"
}
layer {
  name: "shallow_q"
  type: "Concat"
  bottom: "pool1_q2_flat"
  bottom: "pool1_q3_flat"
  top: "shallow_q"
}
layer {
  name: "reshape_shallow_q"
  type: "Reshape"
  bottom: "shallow_q"
  top: "shallow_q_r"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "shallow_q_norm"
  type: "LRN"
  bottom: "shallow_q_r"
  top: "shallow_q_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191.0
    beta: 0.5
  }
}

#P shallow
layer {
  name: "conv1_p2"
  type: "Convolution"
  bottom: "data_p2"
  top: "conv1_p2"
  param {
    name: "conv1_shallow_w2"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_shallow_b2"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 96
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    pad_h: 4
    pad_w: 4
  }
}
layer {
  name: "relu1_p2"
  type: "ReLU"
  bottom: "conv1_p2"
  top: "conv1_p2"
}

layer {
  name: "norm1_p2"
  type: "LRN"
  bottom: "conv1_p2"
  top: "norm1_p2"
  lrn_param {
    local_size: 5
    alpha: 9.99999974738e-05
    beta: 0.75
  }
}
layer {
  name: "pool1_p2"
  type: "Pooling"
  bottom: "norm1_p2"
  top: "pool1_p2"
  pooling_param {
    pool: MAX
    kernel_size: 7
    stride: 4
    pad_h: 3
    pad_w: 3
  }
}

layer {
  name: "conv1_p3"
  type: "Convolution"
  bottom: "data_p3"
  top: "conv1_p3"
  param {
    name: "conv1_shallow_w3"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_shallow_b3"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 96
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    pad_h: 4
    pad_w: 4
  }
}
layer {
  name: "relu1_p3"
  type: "ReLU"
  bottom: "conv1_p3"
  top: "conv1_p3"
}

layer {
  name: "norm1_p3"
  type: "LRN"
  bottom: "conv1_p3"
  top: "norm1_p3"
  lrn_param {
    local_size: 5
    alpha: 9.99999974738e-05
    beta: 0.75
  }
}
layer {
  name: "pool1_p3"
  type: "Pooling"
  bottom: "norm1_p3"
  top: "pool1_p3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 1
    pad_w: 1
  }
}

layer {
  name: "pool1_p2_flat"
  type: "Flatten"
  bottom: "pool1_p2"
  top: "pool1_p2_flat"
}
layer {
  name: "pool1_p3_flat"
  type: "Flatten"
  bottom: "pool1_p3"
  top: "pool1_p3_flat"
}
layer {
  name: "shallow_p"
  type: "Concat"
  bottom: "pool1_p2_flat"
  bottom: "pool1_p3_flat"
  top: "shallow_p"
}
layer {
  name: "reshape_shallow_p"
  type: "Reshape"
  bottom: "shallow_p"
  top: "shallow_p_r"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "shallow_p_norm"
  type: "LRN"
  bottom: "shallow_p_r"
  top: "shallow_p_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191.0
    beta: 0.5
  }
}





#N shallow
layer {
  name: "conv1_n2"
  type: "Convolution"
  bottom: "data_n2"
  top: "conv1_n2"
  param {
    name: "conv1_shallow_w2"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_shallow_b2"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 96
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    pad_h: 4
    pad_w: 4
  }
}
layer {
  name: "relu1_n2"
  type: "ReLU"
  bottom: "conv1_n2"
  top: "conv1_n2"
}

layer {
  name: "norm1_n2"
  type: "LRN"
  bottom: "conv1_n2"
  top: "norm1_n2"
  lrn_param {
    local_size: 5
    alpha: 9.99999974738e-05
    beta: 0.75
  }
}
layer {
  name: "pool1_n2"
  type: "Pooling"
  bottom: "norm1_n2"
  top: "pool1_n2"
  pooling_param {
    pool: MAX
    kernel_size: 7
    stride: 4
    pad_h: 3
    pad_w: 3
  }
}

layer {
  name: "conv1_n3"
  type: "Convolution"
  bottom: "data_n3"
  top: "conv1_n3"
  param {
    name: "conv1_shallow_w3"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "conv1_shallow_b3"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 96
    kernel_size: 8
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.00999999977648
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
    pad_h: 4
    pad_w: 4
  }
}
layer {
  name: "relu1_n3"
  type: "ReLU"
  bottom: "conv1_n3"
  top: "conv1_n3"
}

layer {
  name: "norm1_n3"
  type: "LRN"
  bottom: "conv1_n3"
  top: "norm1_n3"
  lrn_param {
    local_size: 5
    alpha: 9.99999974738e-05
    beta: 0.75
  }
}
layer {
  name: "pool1_n3"
  type: "Pooling"
  bottom: "norm1_n3"
  top: "pool1_n3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 1
    pad_w: 1
  }
}

layer {
  name: "pool1_n2_flat"
  type: "Flatten"
  bottom: "pool1_n2"
  top: "pool1_n2_flat"
}
layer {
  name: "pool1_n3_flat"
  type: "Flatten"
  bottom: "pool1_n3"
  top: "pool1_n3_flat"
}
layer {
  name: "shallow_n"
  type: "Concat"
  bottom: "pool1_n2_flat"
  bottom: "pool1_n3_flat"
  top: "shallow_n"
}
layer {
  name: "reshape_shallow_n"
  type: "Reshape"
  bottom: "shallow_n"
  top: "shallow_n_r"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}
layer {
  name: "shallow_n_norm"
  type: "LRN"
  bottom: "shallow_n_r"
  top: "shallow_n_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191.0
    beta: 0.5
  }
}



layer {
  name: "q_concat"
  type: "Concat"
  bottom: "shallow_q_norm"
  bottom: "fc8_q_norm"
  top: "q_concat"
}
layer {
  name: "linear_embedding_q"
  type: "InnerProduct"
  bottom: "q_concat"
  top: "linear_embedding_q"
  param {
    name: "linear_embedding_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "linear_embedding_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.00499999988824
    }
    bias_filler {
      type: "constant"
      value: 0.10000000149
    }
  }
}

layer {
  name: "reshape_leq"
  type: "Reshape"
  bottom: "linear_embedding_q"
  top:"linear_embedding_q"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}

layer {
  name: "linear_embedding_q_norm"
  type: "LRN"
  bottom: "linear_embedding_q"
  top: "linear_embedding_q_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191.0
    beta: 0.5
  }
}

layer {
  name: "p_concat"
  type: "Concat"
  bottom: "shallow_p_norm"
  bottom: "fc8_p_norm"
  top: "p_concat"
}
layer {
  name: "linear_embedding_p"
  type: "InnerProduct"
  bottom: "p_concat"
  top: "linear_embedding_p"
  param {
    name: "linear_embedding_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "linear_embedding_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.00499999988824
    }
    bias_filler {
      type: "constant"
      value: 0.10000000149
    }
  }
}

layer {
  name: "reshape_lep"
  type: "Reshape"
  bottom: "linear_embedding_p"
  top:"linear_embedding_p"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}

layer {
  name: "linear_embedding_p_norm"
  type: "LRN"
  bottom: "linear_embedding_p"
  top: "linear_embedding_p_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191.0
    beta: 0.5
  }
}

layer {
  name: "n_concat"
  type: "Concat"
  bottom: "shallow_n_norm"
  bottom: "fc8_n_norm"
  top: "n_concat"
}
layer {
  name: "linear_embedding_n"
  type: "InnerProduct"
  bottom: "n_concat"
  top: "linear_embedding_n"
  param {
    name: "linear_embedding_w"
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    name: "linear_embedding_b"
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.00499999988824
    }
    bias_filler {
      type: "constant"
      value: 0.10000000149
    }
  }
}

layer {
  name: "reshape_len"
  type: "Reshape"
  bottom: "linear_embedding_n"
  top:"linear_embedding_n"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: 1
      dim: 1
    }
  }
}

layer {
  name: "linear_embedding_n_norm"
  type: "LRN"
  bottom: "linear_embedding_n"
  top: "linear_embedding_n_norm"
  lrn_param {
    local_size: 8191
    alpha: 8191.0
    beta: 0.5
  }
}

layer {
  name: "pos_el_diff"
  type: "Eltwise"
  bottom: "linear_embedding_q_norm"
  bottom: "linear_embedding_p_norm"
  top: "pos_el_diff"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: -1
  }
}
layer {
  name: "pos_diff_sq"
  bottom: "pos_el_diff"
  top: "pos_diff_sq"
  type: "Power"
  power_param {
    power: 2
    scale: 1
    shift: 0
  }
}

layer {
  name: "pos_dist"
  type: "InnerProduct"
  bottom: "pos_diff_sq"
  top: "pos_dist"
  param {
    name: "pos_dist_w"
    lr_mult: 0
    decay_mult: 0
  }
  param {
    name: "pos_dist_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "neg_el_diff"
  type: "Eltwise"
  bottom: "linear_embedding_q_norm"
  bottom: "linear_embedding_n_norm"
  top: "neg_el_diff"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: -1
  }
}
layer {
  name: "neg_diff_sq"
  bottom: "neg_el_diff"
  top: "neg_diff_sq"
  type: "Power"
  power_param {
    power: 2
    scale: 1
    shift: 0
  }
}

layer {
  name: "neg_dist"
  type: "InnerProduct"
  bottom: "neg_diff_sq"
  top: "neg_dist"
  param {
    name: "neg_dist_w"
    lr_mult: 0
    decay_mult: 0
  }
  param {
    name: "neg_dist_b"
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1
    weight_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "diff"
  type: "Eltwise"
  bottom: "pos_dist"
  bottom: "neg_dist"
  top: "diff"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: -1
  }
}

# TODO Add our caffe version with accuracy_layer
#layer {
#  name: "accuracy"
#  type: "TripletAccuracy"
#  bottom: "diff"
#  top: "accuracy"
#}

layer {
  name: "pos_dist_disp"
  type: "Power"
  bottom: "pos_dist"
  top: "pos_dist_disp"
}
layer {
  name: "neg_dist_disp"
  type: "Power"
  bottom: "neg_dist"
  top: "neg_dist_disp"
}
layer {
  name: "diff_disp"
  type: "Power"
  bottom: "diff"
  top: "diff_disp"
}

layer {
  name: "diff_gap"
  bottom: "diff"
  top: "diff_gap"
  type: "Power"
  power_param {
    power: 1
    scale: 1
    shift: 0.0009
  }
}
layer {
  name: "diff_gap_disp"
  type: "Power"
  bottom: "diff_gap"
  top: "diff_gap_disp"
}
layer {
  name: "hinge_loss"
  type: "ReLU"
  bottom: "diff_gap"
  top: "hinge_loss"
  loss_weight: 1
}
